{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "df_train_ap = pd.read_csv('file://localhost/C:/Users/Bryan/Documents/School/Y3/FYP/UJIndoorLoc/new/df_train_ap.csv')\n",
    "df_train_main = pd.read_csv('file://localhost/C:/Users/Bryan/Documents/School/Y3/FYP/UJIndoorLoc/new/df_train_main.csv')\n",
    "\n",
    "df_test_ap = pd.read_csv('file://localhost/C:/Users/Bryan/Documents/School/Y3/FYP/UJIndoorLoc/new/df_test_ap.csv')\n",
    "df_test_main = pd.read_csv('file://localhost/C:/Users/Bryan/Documents/School/Y3/FYP/UJIndoorLoc/new/df_test_main.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13925, 2])\n",
      "torch.Size([13925, 520])\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "label = df_train_main[[\"x\",\"y\"]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#convert df to tensor object\n",
    "train_t = torch.tensor(df_train_ap.values)\n",
    "\n",
    "label_t = torch.tensor(label.values)\n",
    "\n",
    "#flatten \n",
    "train_t = torch.flatten(train_t,1)\n",
    "\n",
    "label_t = torch.flatten(label_t,1)\n",
    "print(label_t.shape)\n",
    "print(train_t.shape)\n",
    "# print(label_t[0])\n",
    "# print(b1f1_t[0])\n",
    "\n",
    "\n",
    "train_data = [] \n",
    "for i in range(len(train_t)):\n",
    "    train_data.append([train_t[i],label_t[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=100)\n",
    "\n",
    "print(len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6012, 2])\n",
      "torch.Size([6012, 520])\n"
     ]
    }
   ],
   "source": [
    "testlabel = df_test_main[[\"x\",\"y\"]]\n",
    "\n",
    "#df_test_ap = df_test_ap.replace([100],-110)\n",
    "\n",
    "#df_test_ap = df_test_ap.apply(lambda x: (x-x.min())/(x.max()-x.min()), axis=1)\n",
    "\n",
    "\n",
    "#convert df to tensor object\n",
    "test_t = torch.tensor(df_test_ap.values)\n",
    "\n",
    "testlabel_t = torch.tensor(testlabel.values)\n",
    "\n",
    "#flatten \n",
    "test_t = torch.flatten(test_t,1)\n",
    "\n",
    "testlabel_t = torch.flatten(testlabel_t,1)\n",
    "print(testlabel_t.shape)\n",
    "print(test_t.shape)\n",
    "# print(label_t[0])\n",
    "# print(b1f1_t[0])\n",
    "\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader([ [test_t[i], testlabel_t[i]] for i in range(len(testlabel_t))], shuffle=True, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(520,500)\n",
    "        self.fc2 = nn.Linear(500,500)\n",
    "        self.fc3 = nn.Linear(500,500)\n",
    "        self.fc4 = nn.Linear(500,2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #print(x[0][0])\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/50.. Training Loss:1.087.. Test Loss:0.446..\n",
      "Epoch:2/50.. Training Loss:1.024.. Test Loss:0.460..\n",
      "Epoch:3/50.. Training Loss:0.950.. Test Loss:0.388..\n",
      "Epoch:4/50.. Training Loss:0.861.. Test Loss:0.379..\n",
      "Epoch:5/50.. Training Loss:0.859.. Test Loss:0.365..\n",
      "Epoch:6/50.. Training Loss:0.830.. Test Loss:0.362..\n",
      "Epoch:7/50.. Training Loss:0.884.. Test Loss:0.372..\n",
      "Epoch:8/50.. Training Loss:0.846.. Test Loss:0.369..\n",
      "Epoch:9/50.. Training Loss:0.834.. Test Loss:0.379..\n",
      "Epoch:10/50.. Training Loss:0.799.. Test Loss:0.358..\n",
      "Epoch:11/50.. Training Loss:0.823.. Test Loss:0.386..\n",
      "Epoch:12/50.. Training Loss:0.833.. Test Loss:0.354..\n",
      "Epoch:13/50.. Training Loss:0.790.. Test Loss:0.369..\n",
      "Epoch:14/50.. Training Loss:0.771.. Test Loss:0.320..\n",
      "Epoch:15/50.. Training Loss:0.769.. Test Loss:0.320..\n",
      "Epoch:16/50.. Training Loss:0.743.. Test Loss:0.329..\n",
      "Epoch:17/50.. Training Loss:0.742.. Test Loss:0.322..\n",
      "Epoch:18/50.. Training Loss:0.728.. Test Loss:0.311..\n",
      "Epoch:19/50.. Training Loss:0.729.. Test Loss:0.325..\n",
      "Epoch:20/50.. Training Loss:0.735.. Test Loss:0.312..\n",
      "Epoch:21/50.. Training Loss:0.719.. Test Loss:0.305..\n",
      "Epoch:22/50.. Training Loss:0.712.. Test Loss:0.308..\n",
      "Epoch:23/50.. Training Loss:0.713.. Test Loss:0.315..\n",
      "Epoch:24/50.. Training Loss:0.723.. Test Loss:0.307..\n",
      "Epoch:25/50.. Training Loss:0.735.. Test Loss:0.309..\n",
      "Epoch:26/50.. Training Loss:0.709.. Test Loss:0.305..\n",
      "Epoch:27/50.. Training Loss:0.708.. Test Loss:0.319..\n",
      "Epoch:28/50.. Training Loss:0.708.. Test Loss:0.309..\n",
      "Epoch:29/50.. Training Loss:0.713.. Test Loss:0.315..\n",
      "Epoch:30/50.. Training Loss:0.709.. Test Loss:0.313..\n",
      "Epoch:31/50.. Training Loss:0.708.. Test Loss:0.303..\n",
      "Epoch:32/50.. Training Loss:0.705.. Test Loss:0.308..\n",
      "Epoch:33/50.. Training Loss:0.706.. Test Loss:0.307..\n",
      "Epoch:34/50.. Training Loss:0.713.. Test Loss:0.369..\n",
      "Epoch:35/50.. Training Loss:0.712.. Test Loss:0.323..\n",
      "Epoch:36/50.. Training Loss:0.715.. Test Loss:0.305..\n",
      "Epoch:37/50.. Training Loss:0.702.. Test Loss:0.309..\n",
      "Epoch:38/50.. Training Loss:0.706.. Test Loss:0.312..\n",
      "Epoch:39/50.. Training Loss:0.707.. Test Loss:0.298..\n",
      "Epoch:40/50.. Training Loss:0.701.. Test Loss:0.301..\n",
      "Epoch:41/50.. Training Loss:0.763.. Test Loss:0.333..\n",
      "Epoch:42/50.. Training Loss:0.783.. Test Loss:0.338..\n",
      "Epoch:43/50.. Training Loss:0.782.. Test Loss:0.348..\n",
      "Epoch:44/50.. Training Loss:0.795.. Test Loss:0.336..\n",
      "Epoch:45/50.. Training Loss:0.782.. Test Loss:0.335..\n",
      "Epoch:46/50.. Training Loss:0.780.. Test Loss:0.336..\n",
      "Epoch:47/50.. Training Loss:0.799.. Test Loss:0.337..\n",
      "Epoch:48/50.. Training Loss:0.776.. Test Loss:0.332..\n",
      "Epoch:49/50.. Training Loss:0.783.. Test Loss:0.336..\n",
      "Epoch:50/50.. Training Loss:0.770.. Test Loss:0.338..\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, eps = 1e-9) \n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.001, weight_decay=0.03, momentum=0.005)\n",
    "\n",
    "criterion = nn.MSELoss() #MSE\n",
    "#criterion = torch.nn.L1Loss()\n",
    "\n",
    "epochs = 50\n",
    "train_losses, test_losses = [],[]\n",
    "\n",
    "for e in range(epochs):\n",
    "    tot_train_loss = 0 \n",
    "    for data, labels in trainloader:\n",
    "        data = data.view(data.shape[0],-1)\n",
    "        data = data.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #output = ((output - torch.mean(output))/torch.max(output)-torch.min(output))\n",
    "        loss = torch.sqrt(criterion(output,labels.float())) #RMSE \n",
    "        #loss = criterion(output,labels.float())\n",
    "        tot_train_loss+=loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "    else:\n",
    "        tot_test_loss = 0 \n",
    "        with torch.no_grad():\n",
    "            for data, labels in testloader:\n",
    "                data = data.view(data.shape[0],-1)\n",
    "                data=data.float()\n",
    "                test_output = model(data)\n",
    "                loss = torch.sqrt(criterion(test_output,labels.float()))\n",
    "                #loss = criterion(test_output,labels.float())\n",
    "\n",
    "                tot_test_loss+=loss.item()\n",
    "                \n",
    "        train_loss = tot_train_loss/len(trainloader.dataset)\n",
    "        test_loss = tot_test_loss/len(trainloader.dataset)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    " \n",
    "        print(\"Epoch:{}/{}..\".format(e+1,epochs),\n",
    "             \"Training Loss:{:.3f}..\".format(train_loss),\n",
    "             \"Test Loss:{:.3f}..\".format(test_loss))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00955, eps = 1e-9) \n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.001, weight_decay=0.03, momentum=0.005)\n",
    "\n",
    "criterion = nn.MSELoss() #MSE\n",
    "#criterion = torch.nn.L1Loss()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for e in range(epochs):\n",
    "    running_loss = 0 \n",
    "    for data, labels in trainloader:\n",
    "        data = data.view(data.shape[0],-1)\n",
    "        data = data.float()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #output = ((output - torch.mean(output))/torch.max(output)-torch.min(output))\n",
    "\n",
    "        loss = torch.sqrt(criterion(output,labels.float())) #RMSE \n",
    "        #loss = criterion(labels.float(),output)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"labels x: \",(labels[0][0].float()),\"label y: \", (labels[0][1].float()))\n",
    "        print(\"output x: \",(output[0][0].float()),\"output y: \", (output[0][1].float()))\n",
    "        print(\"x DIFF: \",(labels[0][0].float()-output[0][0].float()).abs())\n",
    "        print(\"y DIFF: \",(labels[0][1].float()-output[0][1].float()).abs())\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
