{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import statements"
      ],
      "metadata": {
        "id": "mlXGSPTrYbeY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9sZ2bPcRI_Dr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd \n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn,optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2eqqu-aJAju",
        "outputId": "35b11127-ac15-4037-f671-14722e536c47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model definition "
      ],
      "metadata": {
        "id": "6AwY3NxoYm6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    '''\n",
        "    Returns\n",
        "    ----------\n",
        "    dnn_model : model \n",
        "        structure of the DNN model \n",
        "        \n",
        "        input layer (345, 300) \n",
        "        dropout(.50) \n",
        "        hidden layer1 (300, 300)\n",
        "        dropout(.50)\n",
        "        hidden layer2 (300, 300)\n",
        "        dropout(.50)\n",
        "        output layer (300, 2)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(345,300)\n",
        "        self.fc2 = nn.Linear(300,300)\n",
        "        self.fc3 = nn.Linear(300,300)\n",
        "        self.fc4 = nn.Linear(300,2)\n",
        "\n",
        "        \n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = x.view(x.shape[0],-1)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.dropout(F.relu(self.fc2(x)))\n",
        "        x = self.dropout(F.relu(self.fc3(x)))\n",
        "        x = self.fc4(x)\n",
        "        \n",
        "        return x\n",
        "    "
      ],
      "metadata": {
        "id": "EyeGNjeTJIrq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale & Rescale functions "
      ],
      "metadata": {
        "id": "aFRmHF-8YpKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scale_data(rss_df):\n",
        "    if not('pandas' in str(type(rss_df))):\n",
        "        print(\"ERROR: Please Input Data in pandas.DataFrame\")\n",
        "        return -1\n",
        "\n",
        "    new_rss = rss_df.copy()\n",
        "    new_rss[new_rss == 100] = -110\n",
        "    new_rss[new_rss == -100] = -110\n",
        "\n",
        "    new_rss /= 110\n",
        "    new_rss += 1\n",
        "    return new_rss.values\n",
        "\n",
        "\n",
        "  \n",
        "def rescale_xy(scale_lon_lat, mean, std):\n",
        "    scale_lon_lat = np.array(scale_lon_lat)\n",
        "    lon = np.transpose(np.array([scale_lon_lat[:, 0]]))\n",
        "    # lon = output[0]\n",
        "    lon_rescaled = lon * std[0] + mean[0]\n",
        "\n",
        "    lat = np.transpose(np.array([scale_lon_lat[:, 1]]))\n",
        "    # lat = output[1]\n",
        "    lat_rescaled = lat * std[1] + mean[1]\n",
        "    return np.array([lon_rescaled, lat_rescaled]).transpose().reshape(-1,2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "H0VZx1pUJS62"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load_model & localisation functions "
      ],
      "metadata": {
        "id": "7KWmepp3YsrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_model(model_state): \n",
        "    '''\n",
        "    Load trained model for localisation\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_state: String path of saved model state\n",
        "\n",
        "    Returns model: load it into localisation()\n",
        "    -------\n",
        "\n",
        "    '''\n",
        "    model = Classifier() \n",
        "    model.load_state_dict(torch.load(model_state))\n",
        "    return model     "
      ],
      "metadata": {
        "id": "BlOjq0KSJN1O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def localisation(rssi_list, model): \n",
        "    '''\n",
        "    Parameters\n",
        "    ----------\n",
        "    rssi_list: list containing 345 RSSI values\n",
        "    model: loaded trained model state\n",
        "\n",
        "    Returns a list of predicted location i.e. [longitude, latitude] in EPSG3414\n",
        "    -------\n",
        "\n",
        "    '''\n",
        "    #Very sketchy workabout to use the scale_data function\n",
        "    #convert list into dataframe, call scale_data function, convert back to list \n",
        "    temp_df = pd.DataFrame(rssi_list)\n",
        "    scaled_df = scale_data(temp_df)\n",
        "    temp_list = scaled_df.tolist()\n",
        "    rss = np.array(temp_list)\n",
        "\n",
        "    #hardcoded mean and std \n",
        "    mean = [30032.69349262 ,30317.32534712]\n",
        "    mean_np = np.array(mean)\n",
        "    std = [22.18997454,36.97402449]\n",
        "    std_np = np.array(std)\n",
        "\n",
        "    rss_tensor = torch.from_numpy(rss).reshape(-1,345)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_input = rss_tensor.type(torch.FloatTensor)\n",
        "        predict = model(test_input)\n",
        "        final = rescale_xy(predict.data.numpy(), mean_np, std_np)\n",
        "    return final \n"
      ],
      "metadata": {
        "id": "Qrkem5rGJpnb"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test functions"
      ],
      "metadata": {
        "id": "9WNC1sxJYfuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_val_new = pd.read_csv('/content/drive/MyDrive/FYP/NG/Combined_collections_validation_EPSG3414_filtered.csv')\n",
        "rssi_list = data_val_new.iloc[0,:345].values.tolist() \n",
        "model = load_model(\"/content/drive/MyDrive/FYP/NG/NG_MODEL\")\n",
        "\n",
        "print(localisation(rssi_list, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nb9RfBoXJ33z",
        "outputId": "dc063bc3-40ef-4b60-c68e-c126108a0af5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30056.549 30371.957]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ko4VtkuYM0h0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}