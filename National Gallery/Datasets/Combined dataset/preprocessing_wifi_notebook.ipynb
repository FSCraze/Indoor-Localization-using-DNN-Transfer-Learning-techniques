{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT DIRECTORY HERE (CHANGE THIS)\n",
    "TRAIN_FOLDER = './NG_NEW/Data/training/'\n",
    "TEST_FOLDER = './NG_NEW/Data/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Folders: ['./NG_NEW/Data/training/NGO--2021-08-25-14-54-34--LDL2-2', './NG_NEW/Data/training/NGO--2021-08-25-14-55-13_BElvl2-1', './NG_NEW/Data/training/NGO--2021-08-25-15-09-10--BElvl2-2', './NG_NEW/Data/training/NGO--2021-08-25-15-12-06--L2-JX-R2-Half', './NG_NEW/Data/training/NGO--2021-08-25-15-18-40_LDlvl2C-2', './NG_NEW/Data/training/NGO--2021-08-25-15-24-31_L2-JX-R1-Right', './NG_NEW/Data/training/NGO--2021-08-25-15-24-37_LDlvl2B-1', './NG_NEW/Data/training/NGO--2021-08-25-15-28-11_L2-JX-R2-Right', './NG_NEW/Data/training/NGO--2021-08-25-15-38-59_L2-JX-R1-D', './NG_NEW/Data/training/NGO--2021-08-25-15-49-37_L2-JX-R1-C', './NG_NEW/Data/training/NGO--2021-08-25-15-51-58_LDlvl2D-2', './NG_NEW/Data/training/NGO--2021-08-25-16-39-45_BElvl2-F', './NG_NEW/Data/training/NGO--2021-08-25-16-50-22_L2-JX-F', './NG_NEW/Data/training/NGO--2021-08-25-17-14-41_LDlvl2H2-2', './NG_NEW/Data/training/NGO--2021-08-25-17-44-09_LDlvlB1-1', './NG_NEW/Data/training/NGO--2021-08-25-17-48-57_B1-JX', './NG_NEW/Data/training/NGO--2021-08-25-17-52-50_B1-bryan', './NG_NEW/Data/training/NGO--2021-09-10-09-09-29--L1A-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-09-15-15--L1A-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-15-51_L1B-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-09-21-42_L1B-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-27-37_L1D-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-09-33-47_L1C-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-09-34-14_L1E-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-38-06_L1C-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-43-54_L1D-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-49-01_L1G-LD-1', './NG_NEW/Data/training/NGO--2021-09-10-09-49-17_L1E-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-09-49-18_L1F-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-52-27_L1H-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-54-26_L1H-LD-1', './NG_NEW/Data/training/NGO--2021-09-10-09-54-50_L1G-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-09-57-19_L1F-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-13-32_LB1C-LD-2', './NG_NEW/Data/training/NGO--2021-09-10-10-14-38_LB1-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-14-38_LB1B-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-18-03--LB1A-JX-2', './NG_NEW/Data/training/NGO--2021-09-10-10-19-11--LB1A-LD-1', './NG_NEW/Data/training/NGO--2021-09-10-10-20-15_LB1C-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-21-34_LB1B-JX-2', './NG_NEW/Data/training/NGO--2021-09-10-10-34-29_LB1E-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-42-33_LB1F-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-44-05_LB1F-JX-2', './NG_NEW/Data/training/NGO--2021-09-10-10-46-33_LB1G-JX-1', './NG_NEW/Data/training/NGO--2021-09-10-10-48-37_LB1G-JX-2', './NG_NEW/Data/training/NGO--2021-09-10-10-59-17_LB1D-BE-1', './NG_NEW/Data/training/NGO--2021-09-10-11-04-55_LB1E-BE-1', './NG_NEW/Data/training/NGO--2021-09-10-11-16-43_LB1I-LD-1', './NG_NEW/Data/training/NGO--2021-09-10-11-17-03_LB1H-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-11-20-53_LB1H-WG-2', './NG_NEW/Data/training/NGO--2021-09-10-11-29-17_LB1I-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-11-29-49_L1I-BE-1', './NG_NEW/Data/training/NGO--2021-09-10-11-34-08_L1I-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-11-34-37_L1I-LD-1', './NG_NEW/Data/training/NGO--2021-09-10-11-36-13_L1J-WG-1', './NG_NEW/Data/training/NGO--2021-09-10-11-37-53_L1J-WG-2']\n",
      "\n",
      "Test Folders: ['./NG_NEW/Data/validation/NGO--2021-08-25-15-04-06--L2-JX-R1-Half', './NG_NEW/Data/validation/NGO--2021-08-25-15-15-47_LDLvl2C-1', './NG_NEW/Data/validation/NGO--2021-08-25-15-40-00_LDlvl2D-1', './NG_NEW/Data/validation/NGO--2021-08-25-17-09-26_LDlvl2H2-1', './NG_NEW/Data/validation/NGO--2021-08-25-17-20-08_LDlvl2H1-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-12-33--L1A-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-24-25_L1C-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-27-19_L1B-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-33-36_L1D-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-41-42_L1E-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-51-53_L1F-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-53-59_L1G-JX-1', './NG_NEW/Data/validation/NGO--2021-09-10-09-59-29_L1H-JX-1', './NG_NEW/Data/validation/NGO--2021-09-10-10-12-00_LB1C-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-10-16-20--LB1A-JX-1', './NG_NEW/Data/validation/NGO--2021-09-10-10-16-31_LB1B-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-10-40-26_LB1D-JX-1', './NG_NEW/Data/validation/NGO--2021-09-10-10-48-33_LB1E-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-11-01-58_LB1F-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-11-07-48_LB1G-BE-1', './NG_NEW/Data/validation/NGO--2021-09-10-11-21-15_LB1I-LD-2', './NG_NEW/Data/validation/NGO--2021-09-10-11-27-21_LB1H-LD-1', './NG_NEW/Data/validation/NGO--2021-09-10-11-32-32_L1J-LD-1']\n"
     ]
    }
   ],
   "source": [
    "# Directories for Train\n",
    "f_train = [x[0] for x in os.walk(TRAIN_FOLDER)][1:]\n",
    "print('Train Folders:', f_train)\n",
    "print()\n",
    "\n",
    "# Directories for Test\n",
    "f_test = [x[0] for x in os.walk(TEST_FOLDER)][1:]\n",
    "print('Test Folders:', f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wi-Fi Preprocessing\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe format from column: timestamp | mac | rssi \n",
    "# to dictionary timestamp : mac\n",
    "def create_dict_timestamp_mac(timestamp, df):\n",
    "    result = {}\n",
    "    \n",
    "    for t in timestamp:\n",
    "        sub_df = df[df['timestamp'] == t]\n",
    "        sub_df = sub_df.set_index('mac')\n",
    "        dict_from_df = sub_df.to_dict()['rssi']\n",
    "        \n",
    "        # Remove space infront of mac addr\n",
    "        keys = list(dict_from_df.keys())\n",
    "        for k in keys:\n",
    "            dict_from_df[k[1:]] = dict_from_df[k]\n",
    "            del dict_from_df[k]\n",
    "            \n",
    "        keys = list(dict_from_df.keys())\n",
    "        result[t] = [keys]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionary format timestamp : mac\n",
    "# to dataframe column: unique_mac, row: one_hot, index: timestamp\n",
    "def create_one_hot_mac_df(dt):\n",
    "    df_of_keys = pd.DataFrame.from_dict(dt).T\n",
    "    one_hot = pd.get_dummies(df_of_keys[0].apply(lambda x: pd.Series(1, x)) == 1)\n",
    "    one_hot = one_hot * 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe format from column: unique_mac, row: one_hot, index: timestamp\n",
    "# to dataframe column: unique_mac, row: rssi, index: timestamp\n",
    "def insert_rssi_to_one_hot(timestamp, df, one_hot):\n",
    "    all_mac = set(one_hot.columns)\n",
    "    \n",
    "    for t in timestamp:\n",
    "        sub_df = df[df['timestamp'] == t]\n",
    "        sub_df = sub_df.set_index('mac')\n",
    "        dict_from_df = sub_df.to_dict()['rssi']\n",
    "\n",
    "        keys = list(dict_from_df.keys())\n",
    "        for k in keys:\n",
    "            dict_from_df[k[1:]] = dict_from_df[k]\n",
    "            del dict_from_df[k]\n",
    "\n",
    "        keys = list(dict_from_df.keys())\n",
    "        for k in keys:\n",
    "            one_hot.at[t, k] = dict_from_df[k]\n",
    "\n",
    "        hot_mac = set(keys)\n",
    "        cold_mac = all_mac - hot_mac\n",
    "        cold_keys = list(cold_mac)\n",
    "\n",
    "        for k in cold_keys:\n",
    "            one_hot.at[t, k] = -100\n",
    "            \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Dataset Prep\n",
    "\n",
    "For train_ap.csv:\n",
    "\n",
    "| / | mac_1 | mac_2 | ... | mac_n |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0 | rssi_1 | rssi_2 | ... | rssi_n |\n",
    "\n",
    "- rssi = -100 means that particular AP is not detected for that timestamp\n",
    "\n",
    "For train_main.csv:\n",
    "\n",
    "| / | timestamp | x | y | type |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 0 | timestamp_1 | lat_1 | lng_1 | truth/pseudo |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_ap = None\n",
    "train_main = None\n",
    "for i in range(len(f_train)):\n",
    "    df = pd.read_csv(f_train[i] + '/wifi.csv', header=None)\n",
    "    df_loc = pd.read_csv(f_train[i] + '/ground_truth.csv', header=None)\n",
    "    df.columns = ['timestamp', 'mac', 'rssi']\n",
    "    df_loc.columns = ['timestamp', 'latitude', 'longitude', 'type']\n",
    "    timestamp = df['timestamp'].unique()\n",
    "    dt = create_dict_timestamp_mac(timestamp, df)\n",
    "    new_df = create_one_hot_mac_df(dt)\n",
    "    new_df = insert_rssi_to_one_hot(timestamp, df, new_df)\n",
    "    if(\"B1\" in f_train[i]):\n",
    "#         print(\"B1\")\n",
    "#         print(f_train[i])\n",
    "        new_df[\"floor_id\"] = -1\n",
    "    elif (\"lvl2\" in f_train[i] or \"Lvl2\" in f_train[i] or \"L2\" in f_train[i]): \n",
    "#         print(\"L2\")\n",
    "#         print(f_train[i])\n",
    "        new_df[\"floor_id\"] = 2\n",
    "    elif (\"1\" in f_train[i]):\n",
    "#         print(\"L1\")\n",
    "#         print(f_train[i])   \n",
    "        new_df[\"floor_id\"] = 1\n",
    "\n",
    "    if (i == 0):\n",
    "        train_ap = new_df\n",
    "        train_main = df_loc\n",
    "\n",
    "    else: \n",
    "        train_ap = pd.concat([train_ap, new_df], axis=0)\n",
    "        train_main = pd.concat([train_main, df_loc], axis=0)\n",
    "train_ap = train_ap.fillna(-110)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ap = None\n",
    "test_main = None\n",
    "\n",
    "for i in range(len(f_test)):\n",
    "    df = pd.read_csv(f_test[i] + '/wifi.csv', header=None)\n",
    "    df_loc = pd.read_csv(f_test[i] + '/ground_truth.csv', header=None)\n",
    "    df.columns = ['timestamp', 'mac', 'rssi']\n",
    "    df_loc.columns = ['timestamp', 'latitude', 'longitude', 'type']\n",
    "    timestamp = df['timestamp'].unique()\n",
    "    dt = create_dict_timestamp_mac(timestamp, df)\n",
    "    new_df = create_one_hot_mac_df(dt)\n",
    "    new_df = insert_rssi_to_one_hot(timestamp, df, new_df)\n",
    "    if(\"B1\" in f_test[i]):\n",
    "        new_df[\"floor_id\"] = -1\n",
    "    elif (\"lvl2\" in f_train[i] or \"Lvl2\" in f_train[i] or \"L2\" in f_train[i]): \n",
    "        new_df[\"floor_id\"] = 2\n",
    "    elif (\"1\" in f_test[i]):\n",
    "        new_df[\"floor_id\"] = 1\n",
    "    if (i == 0):\n",
    "        test_ap = new_df\n",
    "        test_main = df_loc\n",
    "    else: \n",
    "        test_ap = pd.concat([test_ap, new_df], axis=0)\n",
    "        test_main = pd.concat([test_main, df_loc], axis=0)\n",
    "    \n",
    "test_ap = test_ap.fillna(-110)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare AP List for train & test\n",
    "test_column_set = set(test_ap.columns)\n",
    "train_column_set = set(train_ap.columns)\n",
    "diff_column_set = test_column_set.symmetric_difference(train_column_set)\n",
    "to_add_to_test = list(diff_column_set - test_column_set)\n",
    "to_remove_from_test = list(diff_column_set - train_column_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add APs that is Present in train but Absent in test\n",
    "for m in to_add_to_test:\n",
    "    test_ap.insert(0, m, [-100] * len(test_ap.index), allow_duplicates=False)\n",
    "    \n",
    "# Drop APs that is Present in test but Absent in train\n",
    "test_ap = test_ap.drop(to_remove_from_test, axis=1)\n",
    "\n",
    "# Ensure that the Column Order of train and test in the Same\n",
    "test_ap = test_ap[train_ap.columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bryan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_combined = pd.concat([test_ap,test_main], axis=0,ignore_index=True, join=\"outer\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAP tagging + rename column header \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         AP                MAC\n",
      "0      WAP0  00:1e:42:27:86:00\n",
      "1      WAP1  00:1e:42:2d:25:66\n",
      "2      WAP2  00:1e:42:2f:d8:64\n",
      "3      WAP3  00:1e:42:34:2c:8d\n",
      "4      WAP4  00:1e:42:35:b2:fa\n",
      "..      ...                ...\n",
      "842  WAP842  f0:41:c8:e0:43:a6\n",
      "843  WAP843  f0:9f:c2:3a:f3:55\n",
      "844  WAP844  f8:d0:27:78:ab:20\n",
      "845  WAP845  fa:1d:10:cc:2f:dc\n",
      "846  WAP846  fa:d0:27:68:51:9c\n",
      "\n",
      "[847 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_mac = list(test_ap.columns.values.tolist())\n",
    "train_mac = list(train_ap.columns.values.tolist())\n",
    "test_mac.pop()\n",
    "train_mac.pop()\n",
    "\n",
    "\n",
    "ap_number = []\n",
    "for i in range(len(test_mac)):\n",
    "    ap_number.append(f\"WAP{i}\")\n",
    "\n",
    "\n",
    "d = {\"AP\":ap_number, \"MAC\": train_mac}\n",
    "\n",
    "ap_list = pd.DataFrame(data=d)\n",
    "print(ap_list)\n",
    "\n",
    "ap_list.to_csv(index=False, path_or_buf=\"./combined/AP_index.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = dict(zip(test_mac,ap_number))\n",
    "test_combined = test_combined.rename(columns=dict1)\n",
    "train_combined= train_combined.rename(columns=dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined.to_csv(index=False, path_or_buf='./combined/test_combined.csv')\n",
    "train_combined.to_csv(index=False, path_or_buf='./combined/train_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
